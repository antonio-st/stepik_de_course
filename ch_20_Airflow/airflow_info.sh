Запуск образа
 Создайте  главную папку для вашего проекта Airflow. Например, airflow_project
Внутри этой папки создайте три подпапки: dags, logs, и plugins

   Необходимо скачать файл docker-compose.yaml
   https://airflow.apache.org/docs/apache-airflow/2.9.2/docker-compose.yaml

    и поместить его в папку airflow_project.

docker-compose up airflow-init
docker-compose up -d


Параметры Default Args

Параметры default_args используются для определения значений по умолчанию для атрибутов в объекте DAG (Directed Acyclic Graph) в Apache Airflow. Эти параметры могут быть применены ко всем задачам (операторам) внутри этого DAG, если для них не указаны собственные значения. Вот некоторые распространенные параметры default_args:

1.      owner (str): Владелец или автор DAG. Это имя пользователя или группы, ответственных за данный DAG.

2.      depends_on_past (bool): Определяет, зависит ли выполнение каждой задачи от успешного завершения ее предыдущей итерации (если True).

3.      start_date (datetime): Дата и время, с которой начинается выполнение DAG. Это может быть указано как строка в формате 'YYYY-MM-DD' или объект datetime.

4.      end_date (datetime): Дата и время, после которых выполнение DAG больше не будет запускаться. Обычно используется для установки конечного срока выполнения DAG.

5.      retries (int): Количество попыток выполнения задачи в случае ошибки.

6.      retry_delay (timedelta): Время задержки между попытками выполнения задачи в случае ошибки.

7.      email (str): Адрес электронной почты, на который будут отправляться уведомления о статусе выполнения DAG.

8.      email_on_failure (bool): Указывает, следует ли отправлять уведомления о неудачных попытках выполнения задачи по электронной почте.

9.      email_on_retry (bool): Указывает, следует ли отправлять уведомления о повторных попытках выполнения задачи по электронной почте.

10.  schedule_interval (str or timedelta): Интервал, с которым запускается DAG. Может быть строкой в формате «cron» или объектом timedelta.

11.  max_active_runs (int): Максимальное количество активных запусков DAG одновременно.

 

12.  catchup (bool): Определяет, должен ли DAG выполнять задачи для пропущенных интервалов времени, если это включено.


Переменные (Variables): Переменные в Airflow представляют собой ключ-значение пары, которые могут быть использованы для хранения конфигурационных данных и параметров, доступных в вашем рабочем процессе. Некоторые примеры использования переменных могут включать настройки подключения к базе данных, настройки авторизации и другие параметры, которые могут меняться в зависимости от окружения выполнения. Переменные можно определить и настроить через веб-интерфейс Airflow или использовать API для программного управления ими. Для доступа к переменным в коде задачи вы можете использовать объект Variable модуля airflow.models.



Подключения (Connections): Подключения в Airflow представляют собой параметры, необходимые для установки связи с внешними источниками данных, такими как базы данных, сервисы облачных провайдеров, API и другие ресурсы. Эти параметры, такие как хост, порт, имя пользователя, пароль и другие, могут быть настроены и управляются в веб-интерфейсе Airflow или через API. Подключения в Airflow могут быть использованы в коде задач для установки соединения с внешними источниками данных. Для доступа к подключениям в коде задачи вы можете использовать объект Connection модуля airflow.hooks.base.

XCom: XCom (Cross Communication) в Airflow представляет собой механизм обмена данными между задачами внутри рабочего процесса. XCom позволяет передавать и получать данные между задачами в виде ключ-значение пары. Это может быть полезно, когда вам нужно передать результат выполнения одной задачи в другую задачу для дальнейшей обработки. Задачи могут читать и записывать XCom значения с использованием методов xcom_pull() и xcom_push() соответственно. Для доступа к XCom значениям в коде задачи вы можете использовать объект context (контекст выполнения) и методы модуля airflow.models.




1. Создание подключений через веб-интерфейс Airflow:

    Перейдите в веб-интерфейс Airflow ( доступен по адресу http://localhost:8080).
    В меню выберите «Admin» и затем «Connections».
    Нажмите кнопку «Create» или «Add Connection».
    Заполните поля для подключения, такие как Conn Id (идентификатор подключения), Conn Type (тип подключения), Host, Port, Login, Password и другие, в зависимости от типа подключения.
    Нажмите кнопку «Save» или «Add».


